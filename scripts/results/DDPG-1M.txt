[ec2-user@ip-172-31-4-206 ~]$ screen -r


Interval 89 (880000 steps performed)
10000/10000 [==============================] - 1963s - reward: 0.0089
59 episodes - episode_reward: 1.510 [0.002, 1.888] - loss: 0.000 - mean_absolute_error: 0.012 - mean_q: 0.658

Interval 90 (890000 steps performed)
10000/10000 [==============================] - 4443s - reward: 0.0087
74 episodes - episode_reward: 1.155 [0.138, 2.249] - loss: 0.000 - mean_absolute_error: 0.012 - mean_q: 0.670

Interval 91 (900000 steps performed)
10000/10000 [==============================] - 6373s - reward: 0.0076
90 episodes - episode_reward: 0.845 [-0.200, 2.381] - loss: 0.000 - mean_absolute_error: 0.012 - mean_q: 0.680

Interval 92 (910000 steps performed)
10000/10000 [==============================] - 3938s - reward: 0.0086
55 episodes - episode_reward: 1.575 [-0.071, 2.488] - loss: 0.000 - mean_absolute_error: 0.012 - mean_q: 0.683

Interval 93 (920000 steps performed)
10000/10000 [==============================] - 2391s - reward: 0.0059
55 episodes - episode_reward: 1.069 [-0.180, 1.906] - loss: 0.000 - mean_absolute_error: 0.012 - mean_q: 0.680

Interval 94 (930000 steps performed)
10000/10000 [==============================] - 3108s - reward: 0.0075
55 episodes - episode_reward: 1.354 [-0.083, 1.745] - loss: 0.000 - mean_absolute_error: 0.011 - mean_q: 0.673

Interval 95 (940000 steps performed)
10000/10000 [==============================] - 7038s - reward: 0.0095
75 episodes - episode_reward: 1.285 [0.695, 1.570] - loss: 0.000 - mean_absolute_error: 0.011 - mean_q: 0.675

Interval 96 (950000 steps performed)
10000/10000 [==============================] - 5008s - reward: 0.0087
58 episodes - episode_reward: 1.497 [0.036, 2.140] - loss: 0.000 - mean_absolute_error: 0.011 - mean_q: 0.681

Interval 97 (960000 steps performed)
10000/10000 [==============================] - 1444s - reward: 0.0066
36 episodes - episode_reward: 1.814 [0.402, 2.478] - loss: 0.000 - mean_absolute_error: 0.011 - mean_q: 0.676

Interval 98 (970000 steps performed)
10000/10000 [==============================] - 5345s - reward: 0.0054
53 episodes - episode_reward: 1.029 [-0.216, 2.351] - loss: 0.000 - mean_absolute_error: 0.010 - mean_q: 0.666

Interval 99 (980000 steps performed)
10000/10000 [==============================] - 2397s - reward: 0.0054
50 episodes - episode_reward: 1.071 [-0.328, 2.357] - loss: 0.000 - mean_absolute_error: 0.011 - mean_q: 0.663

Interval 100 (990000 steps performed)
10000/10000 [==============================] - 1303s - reward: 0.0025
done, took 235948.048 seconds